{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/23 16:37:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/12/23 16:37:44 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching FX rates for 2024-12-01 to 2024-12-01.\n",
      "Error on 2024-12-01: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-02 to 2024-12-02.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-03 to 2024-12-03.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-04 to 2024-12-04.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-05 to 2024-12-05.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-06 to 2024-12-06.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-07 to 2024-12-07.\n",
      "Error on 2024-12-07: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-08 to 2024-12-08.\n",
      "Error on 2024-12-08: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-09 to 2024-12-09.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-10 to 2024-12-10.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-11 to 2024-12-11.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-12 to 2024-12-12.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-13 to 2024-12-13.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-14 to 2024-12-14.\n",
      "Error on 2024-12-14: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-15 to 2024-12-15.\n",
      "Error on 2024-12-15: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-16 to 2024-12-16.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-17 to 2024-12-17.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-18 to 2024-12-18.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-19 to 2024-12-19.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-20 to 2024-12-20.\n",
      "Processing FX rates.\n",
      "Writing FX rates to PostgreSQL.\n",
      "Fetching FX rates for 2024-12-21 to 2024-12-21.\n",
      "Error on 2024-12-21: No columns to parse from file\n",
      "Fetching FX rates for 2024-12-22 to 2024-12-22.\n",
      "Error on 2024-12-22: No columns to parse from file\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime, timedelta\n",
    "import psycopg2\n",
    "import io\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FX Rates Loader with Metadata\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    \"dbname\": \"warehouse\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"root\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "# ECB API details\n",
    "entrypoint = \"https://sdw-wsrest.ecb.europa.eu/service/\"\n",
    "resource = \"data\"\n",
    "flowRef = \"EXR\"\n",
    "key = \"D..EUR.SP00.A\"\n",
    "base_url = f\"{entrypoint}{resource}/{flowRef}/{key}\"\n",
    "\n",
    "# Fetch the last run date from metadata table\n",
    "def get_last_run_date():\n",
    "    with psycopg2.connect(**db_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT COALESCE(MAX(last_run_date), '2024-12-01') FROM metadata\")\n",
    "            last_run_date = cur.fetchone()[0]\n",
    "    # Handle the case where last_run_date is a datetime.date\n",
    "    if isinstance(last_run_date, datetime):\n",
    "        return last_run_date\n",
    "    elif isinstance(last_run_date, date):  # Convert date to datetime\n",
    "        return datetime.combine(last_run_date, datetime.min.time())\n",
    "    elif isinstance(last_run_date, str):  # Parse string into datetime\n",
    "        return datetime.strptime(last_run_date, \"%Y-%m-%d\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported date format in metadata table.\")\n",
    "\n",
    "\n",
    "# Update the metadata table\n",
    "def update_metadata(run_date, is_successful, error_message=None):\n",
    "    with psycopg2.connect(**db_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO metadata (last_run_date, is_successful, error_message)\n",
    "                VALUES (%s, %s, %s)\n",
    "                \"\"\",\n",
    "                (run_date, is_successful, error_message),\n",
    "            )\n",
    "            conn.commit()\n",
    "\n",
    "# Fetch the FX data as a Pandas DataFrame\n",
    "def fetch_fx_rates(start_date, end_date):\n",
    "    params = {\n",
    "        \"startPeriod\": start_date,\n",
    "        \"endPeriod\": end_date,\n",
    "        \"dimensionAtObservation\": \"AllDimensions\"\n",
    "    }\n",
    "    response = requests.get(base_url, params=params, headers={\"Accept\": \"text/csv\"})\n",
    "    if response.status_code == 200:\n",
    "        return pd.read_csv(io.StringIO(response.text))\n",
    "    else:\n",
    "        raise Exception(f\"API call failed with status {response.status_code}\")\n",
    "\n",
    "# Process FX rates for a specific currency\n",
    "def process_fx_rates(data, target_currency=\"USD\"):\n",
    "    df = data.filter([\"TIME_PERIOD\", \"CURRENCY\", \"OBS_VALUE\"], axis=1)\n",
    "    df[\"TIME_PERIOD\"] = pd.to_datetime(df[\"TIME_PERIOD\"])\n",
    "    df = df.set_index(\"TIME_PERIOD\")\n",
    "    df = df[df[\"CURRENCY\"] == target_currency]\n",
    "    return df\n",
    "\n",
    "# Write FX rates to PostgreSQL\n",
    "def write_fx_rates_to_postgresql(dataframe, table_name):\n",
    "    with psycopg2.connect(**db_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for _, row in dataframe.iterrows():\n",
    "                cur.execute(\n",
    "                    f\"\"\"\n",
    "                    INSERT INTO {table_name} (currency_code, exchange_rate, valid_date, source, timestamp)\n",
    "                    VALUES (%s, %s, %s, %s, NOW())\n",
    "                    \"\"\",\n",
    "                    (row[\"CURRENCY\"], row[\"OBS_VALUE\"], row.name.date(), \"ECB\"),\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "# Main loop for fetching and saving FX data\n",
    "try:\n",
    "    start_date = get_last_run_date()\n",
    "    end_date = datetime.now() - timedelta(days=1)\n",
    "    current_date = start_date\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        try:\n",
    "            # Set date ranges for API call\n",
    "            start_period = current_date.strftime(\"%Y-%m-%d\")\n",
    "            end_period = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "            print(f\"Fetching FX rates for {start_period} to {end_period}.\")\n",
    "            raw_data = fetch_fx_rates(start_period, end_period)\n",
    "\n",
    "            if raw_data.empty:\n",
    "                print(f\"No data received for {start_period}. Skipping.\")\n",
    "                update_metadata(current_date.strftime(\"%Y-%m-%d\"), True, \"No data\")\n",
    "            else:\n",
    "                print(\"Processing FX rates.\")\n",
    "                fx_data = process_fx_rates(raw_data)\n",
    "\n",
    "                if fx_data.empty:\n",
    "                    print(f\"No valid data for {start_period}. Skipping.\")\n",
    "                    update_metadata(current_date.strftime(\"%Y-%m-%d\"), True, \"No valid data\")\n",
    "                else:\n",
    "                    print(\"Writing FX rates to PostgreSQL.\")\n",
    "                    write_fx_rates_to_postgresql(fx_data, \"exchange_rates\")\n",
    "\n",
    "                    # Update metadata for successful processing\n",
    "                    update_metadata(current_date.strftime(\"%Y-%m-%d\"), True)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Update metadata with failure details\n",
    "            update_metadata(current_date.strftime(\"%Y-%m-%d\"), False, str(e))\n",
    "            print(f\"Error on {current_date.strftime('%Y-%m-%d')}: {e}\")\n",
    "\n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "except Exception as main_e:\n",
    "    print(f\"Main loop failed: {main_e}\")\n",
    "finally:\n",
    "    spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
